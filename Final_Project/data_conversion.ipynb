{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be32242c",
   "metadata": {},
   "source": [
    "# Data Conversion\n",
    "\n",
    "This notebook transforms our soundfiles into a numerical dataset for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f6c9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potentially needed installations\n",
    "#!pip install librosa\n",
    "# !pip install playsound\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a21d7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "#from playsound import playsound\n",
    "#This is used to show a progress bar in the terminal. Helpful as the conversion can take a while.\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b459f8",
   "metadata": {},
   "source": [
    "## Preparation of the Overview Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d108f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_overview(list_of_files, folder_path=None):\n",
    "    \"\"\"\n",
    "    This function takes a list of files and creates a joint dataframe for audio file conversion\n",
    "    \"\"\"\n",
    "    overview = None\n",
    "    for file in list_of_files:\n",
    "        file_path = f\"{folder_path}/{file}\" if folder_path else file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            if overview is None:\n",
    "                overview = pd.read_csv(file, sep=\"\\t\", dtype={'sentence_domain': str}, low_memory=False)\n",
    "            else:\n",
    "                overview = pd.concat([overview, pd.read_csv(file, sep=\"\\t\", dtype={'sentence_domain': str}, low_memory=False)], ignore_index=True)\n",
    "    return overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02879d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gender(gender):\n",
    "    if gender == \"male\":\n",
    "        return \"male_masculine\"\n",
    "    elif gender == \"female\":\n",
    "        return \"female_feminine\"\n",
    "    else:\n",
    "        return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1986b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_overview(overview, f_path):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and preprocesses it for audio file conversion\n",
    "    \"\"\"\n",
    "    # we only need files with a gender label\n",
    "    overview = overview.dropna(subset=[\"gender\"])\n",
    "    # irrelevant columns for our analysis\n",
    "    overview = overview.drop(columns=[\"variant\", \"segment\", \"sentence_id\", \"up_votes\", \"down_votes\"])\n",
    "    # fixing gender labels\n",
    "    overview[\"gender\"] = overview[\"gender\"].apply(fix_gender)\n",
    "    # dropping all files that are not simply male or female\n",
    "    overview = overview[(overview[\"gender\"] == \"female_feminine\") | (overview[\"gender\"] == \"male_masculine\")]\n",
    "    # limiting to a maximum of 5 random clips per client_id\n",
    "    overview = overview.groupby(\"client_id\").apply(lambda group: group.sample(n=min(len(group), 5), random_state=42)).reset_index(drop=True)\n",
    "    # changing the path to reflect the location of the audio files\n",
    "    overview[\"path\"] = overview[\"path\"].apply(lambda x: f\"{f_path}/{x}\")\n",
    "    return overview.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2eb98bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1569569 entries, 0 to 1569568\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   client_id        1569569 non-null  object \n",
      " 1   path             1569569 non-null  object \n",
      " 2   sentence_id      1569569 non-null  object \n",
      " 3   sentence         1569566 non-null  object \n",
      " 4   sentence_domain  105 non-null      object \n",
      " 5   up_votes         1569569 non-null  int64  \n",
      " 6   down_votes       1569569 non-null  int64  \n",
      " 7   age              1377285 non-null  object \n",
      " 8   gender           1371150 non-null  object \n",
      " 9   accents          1204289 non-null  object \n",
      " 10  variant          0 non-null        float64\n",
      " 11  locale           1569569 non-null  object \n",
      " 12  segment          63496 non-null    object \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 155.7+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "client_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentence_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentence_domain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "up_votes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "down_votes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "accents",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "variant",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "locale",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "segment",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3b0f3b35-a379-4ef4-b0e9-456e1d1b9c6e",
       "rows": [
        [
         "count",
         "1569569",
         "1569569",
         "1569569",
         "1569566",
         "105",
         "1569569.0",
         "1569569.0",
         "1377285",
         "1371150",
         "1204289",
         "0.0",
         "1569569",
         "63496"
        ],
        [
         "unique",
         "25685",
         "1569569",
         "1036205",
         "1036050",
         "19",
         null,
         null,
         "9",
         "3",
         "187",
         null,
         "1",
         "1"
        ],
        [
         "top",
         "a97730f86fa90560ae105669364412a9ad393b32839d0151236604af188212aab60bf5168a7975fdd0a448dd3131543f5c0032e737a7164b41e9d9d85ffd6660",
         "common_voice_es_42688245.mp3",
         "ad51886652f88e4d616d47ac4a2c80861588b150feae4cc645b9aaab359fa80f",
         "siete",
         "general",
         null,
         null,
         "twenties",
         "male_masculine",
         "MÃ©xico",
         null,
         "es",
         "Benchmark"
        ],
        [
         "freq",
         "146108",
         "1",
         "4659",
         "4659",
         "24",
         null,
         null,
         "836579",
         "872916",
         "833169",
         null,
         "1569569",
         "63496"
        ],
        [
         "mean",
         null,
         null,
         null,
         null,
         null,
         "0.6457817400827871",
         "0.054641751971401066",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "std",
         null,
         null,
         null,
         null,
         null,
         "1.0486085085226033",
         "0.2622992733021779",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "min",
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25%",
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "50%",
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "0.0",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "75%",
         null,
         null,
         null,
         null,
         null,
         "2.0",
         "0.0",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "max",
         null,
         null,
         null,
         null,
         null,
         "19.0",
         "18.0",
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_domain</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1569569</td>\n",
       "      <td>1569569</td>\n",
       "      <td>1569569</td>\n",
       "      <td>1569566</td>\n",
       "      <td>105</td>\n",
       "      <td>1.569569e+06</td>\n",
       "      <td>1.569569e+06</td>\n",
       "      <td>1377285</td>\n",
       "      <td>1371150</td>\n",
       "      <td>1204289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1569569</td>\n",
       "      <td>63496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25685</td>\n",
       "      <td>1569569</td>\n",
       "      <td>1036205</td>\n",
       "      <td>1036050</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a97730f86fa90560ae105669364412a9ad393b32839d01...</td>\n",
       "      <td>common_voice_es_42688245.mp3</td>\n",
       "      <td>ad51886652f88e4d616d47ac4a2c80861588b150feae4c...</td>\n",
       "      <td>siete</td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>MÃ©xico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>Benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>146108</td>\n",
       "      <td>1</td>\n",
       "      <td>4659</td>\n",
       "      <td>4659</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>836579</td>\n",
       "      <td>872916</td>\n",
       "      <td>833169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1569569</td>\n",
       "      <td>63496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.457817e-01</td>\n",
       "      <td>5.464175e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.048609e+00</td>\n",
       "      <td>2.622993e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id  \\\n",
       "count                                             1569569   \n",
       "unique                                              25685   \n",
       "top     a97730f86fa90560ae105669364412a9ad393b32839d01...   \n",
       "freq                                               146108   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                path  \\\n",
       "count                        1569569   \n",
       "unique                       1569569   \n",
       "top     common_voice_es_42688245.mp3   \n",
       "freq                               1   \n",
       "mean                             NaN   \n",
       "std                              NaN   \n",
       "min                              NaN   \n",
       "25%                              NaN   \n",
       "50%                              NaN   \n",
       "75%                              NaN   \n",
       "max                              NaN   \n",
       "\n",
       "                                              sentence_id sentence  \\\n",
       "count                                             1569569  1569566   \n",
       "unique                                            1036205  1036050   \n",
       "top     ad51886652f88e4d616d47ac4a2c80861588b150feae4c...    siete   \n",
       "freq                                                 4659     4659   \n",
       "mean                                                  NaN      NaN   \n",
       "std                                                   NaN      NaN   \n",
       "min                                                   NaN      NaN   \n",
       "25%                                                   NaN      NaN   \n",
       "50%                                                   NaN      NaN   \n",
       "75%                                                   NaN      NaN   \n",
       "max                                                   NaN      NaN   \n",
       "\n",
       "       sentence_domain      up_votes    down_votes       age          gender  \\\n",
       "count              105  1.569569e+06  1.569569e+06   1377285         1371150   \n",
       "unique              19           NaN           NaN         9               3   \n",
       "top            general           NaN           NaN  twenties  male_masculine   \n",
       "freq                24           NaN           NaN    836579          872916   \n",
       "mean               NaN  6.457817e-01  5.464175e-02       NaN             NaN   \n",
       "std                NaN  1.048609e+00  2.622993e-01       NaN             NaN   \n",
       "min                NaN  0.000000e+00  0.000000e+00       NaN             NaN   \n",
       "25%                NaN  0.000000e+00  0.000000e+00       NaN             NaN   \n",
       "50%                NaN  0.000000e+00  0.000000e+00       NaN             NaN   \n",
       "75%                NaN  2.000000e+00  0.000000e+00       NaN             NaN   \n",
       "max                NaN  1.900000e+01  1.800000e+01       NaN             NaN   \n",
       "\n",
       "        accents  variant   locale    segment  \n",
       "count   1204289      0.0  1569569      63496  \n",
       "unique      187      NaN        1          1  \n",
       "top      MÃ©xico      NaN       es  Benchmark  \n",
       "freq     833169      NaN  1569569      63496  \n",
       "mean        NaN      NaN      NaN        NaN  \n",
       "std         NaN      NaN      NaN        NaN  \n",
       "min         NaN      NaN      NaN        NaN  \n",
       "25%         NaN      NaN      NaN        NaN  \n",
       "50%         NaN      NaN      NaN        NaN  \n",
       "75%         NaN      NaN      NaN        NaN  \n",
       "max         NaN      NaN      NaN        NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_files = [\"validated.tsv\",\"other.tsv\"]\n",
    "folder_path_danish=\"./data/cv-corpus-21.0-2025-03-14/da\"\n",
    "folder_path_swedish=\"./data/cv-corpus-21.0-2025-03-14/sv-SE\"\n",
    "folder_path_german=\"./data/cv-corpus-21.0-2025-03-14/de\"\n",
    "folder_path_french=\"./data/cv-corpus-21.0-2025-03-14/fr\"\n",
    "folder_path_spanish=\"./data/cv-corpus-21.0-2025-03-14/es\"\n",
    "folder_path_english=\"./data/cv-corpus-21.0-2025-03-14/en\"\n",
    "folder_path=folder_path_spanish\n",
    "overview = prepare_overview(list_of_files,folder_path)\n",
    "overview.info()\n",
    "overview.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c532c6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "do_not_wish_to_say         5\n",
       "female_feminine       498229\n",
       "male_masculine        872916\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.groupby(\"gender\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0223729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6234"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overview.dropna(subset=[\"gender\"])[\"client_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c732f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_42468\\1923579572.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  overview = overview.groupby(\"client_id\").apply(lambda group: group.sample(n=min(len(group), 5), random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "client_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence_domain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "accents",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "locale",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "342fb47e-d8cb-45e6-b6ba-5614f4af69d1",
       "rows": [
        [
         "10712",
         "5d616fbeb235ea174cc73794b8f3ef28be4d414a941d428798511deb57f2eca502aaf1d69a4c1f9346293b81f172879eac5eceb2ec771a4af5d3fc1f4e0274bb",
         "clips/common_voice_es_18306566.mp3",
         "se lo daremos , seÃ±or ... y despuÃ©s la corona de EspaÃ±a .",
         null,
         "thirties",
         "male_masculine",
         "EspaÃ±a: Norte peninsular (Asturias, Castilla y LeÃ³n, Cantabria, PaÃ­s Vasco, Navarra, AragÃ³n, La Rioja, Guadalajara, Cuenca)",
         "es"
        ],
        [
         "10711",
         "5d616fbeb235ea174cc73794b8f3ef28be4d414a941d428798511deb57f2eca502aaf1d69a4c1f9346293b81f172879eac5eceb2ec771a4af5d3fc1f4e0274bb",
         "clips/common_voice_es_18306604.mp3",
         "salieron nueve mercantes , cuatro pesqueros de altura ,",
         null,
         "thirties",
         "male_masculine",
         "EspaÃ±a: Norte peninsular (Asturias, Castilla y LeÃ³n, Cantabria, PaÃ­s Vasco, Navarra, AragÃ³n, La Rioja, Guadalajara, Cuenca)",
         "es"
        ],
        [
         "10713",
         "5d616fbeb235ea174cc73794b8f3ef28be4d414a941d428798511deb57f2eca502aaf1d69a4c1f9346293b81f172879eac5eceb2ec771a4af5d3fc1f4e0274bb",
         "clips/common_voice_es_18307339.mp3",
         "los bosques de Campeche ,",
         null,
         "thirties",
         "male_masculine",
         "EspaÃ±a: Norte peninsular (Asturias, Castilla y LeÃ³n, Cantabria, PaÃ­s Vasco, Navarra, AragÃ³n, La Rioja, Guadalajara, Cuenca)",
         "es"
        ],
        [
         "16377",
         "8d9937b88227497ab43d9eebdea32b61100f53e7c749e32ba444f55316a37caa584e2a8c10ccc825934ffb268a7d01efcc88377d8133a0da9c0ee0b97d5e183b",
         "clips/common_voice_es_18307761.mp3",
         "y callÃ³ , tal vez esperando una disculpa amante , pero yo preferÃ­ guardar silencio ,",
         null,
         "fifties",
         "male_masculine",
         null,
         "es"
        ],
        [
         "16375",
         "8d9937b88227497ab43d9eebdea32b61100f53e7c749e32ba444f55316a37caa584e2a8c10ccc825934ffb268a7d01efcc88377d8133a0da9c0ee0b97d5e183b",
         "clips/common_voice_es_18307940.mp3",
         "pero yo hijos no te voy a dar .",
         null,
         "fifties",
         "male_masculine",
         null,
         "es"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_domain</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...</td>\n",
       "      <td>clips/common_voice_es_18306566.mp3</td>\n",
       "      <td>se lo daremos , seÃ±or ... y despuÃ©s la corona ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>EspaÃ±a: Norte peninsular (Asturias, Castilla y...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10711</th>\n",
       "      <td>5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...</td>\n",
       "      <td>clips/common_voice_es_18306604.mp3</td>\n",
       "      <td>salieron nueve mercantes , cuatro pesqueros de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>EspaÃ±a: Norte peninsular (Asturias, Castilla y...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10713</th>\n",
       "      <td>5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...</td>\n",
       "      <td>clips/common_voice_es_18307339.mp3</td>\n",
       "      <td>los bosques de Campeche ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>EspaÃ±a: Norte peninsular (Asturias, Castilla y...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>8d9937b88227497ab43d9eebdea32b61100f53e7c749e3...</td>\n",
       "      <td>clips/common_voice_es_18307761.mp3</td>\n",
       "      <td>y callÃ³ , tal vez esperando una disculpa amant...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16375</th>\n",
       "      <td>8d9937b88227497ab43d9eebdea32b61100f53e7c749e3...</td>\n",
       "      <td>clips/common_voice_es_18307940.mp3</td>\n",
       "      <td>pero yo hijos no te voy a dar .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               client_id  \\\n",
       "10712  5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...   \n",
       "10711  5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...   \n",
       "10713  5d616fbeb235ea174cc73794b8f3ef28be4d414a941d42...   \n",
       "16377  8d9937b88227497ab43d9eebdea32b61100f53e7c749e3...   \n",
       "16375  8d9937b88227497ab43d9eebdea32b61100f53e7c749e3...   \n",
       "\n",
       "                                     path  \\\n",
       "10712  clips/common_voice_es_18306566.mp3   \n",
       "10711  clips/common_voice_es_18306604.mp3   \n",
       "10713  clips/common_voice_es_18307339.mp3   \n",
       "16377  clips/common_voice_es_18307761.mp3   \n",
       "16375  clips/common_voice_es_18307940.mp3   \n",
       "\n",
       "                                                sentence sentence_domain  \\\n",
       "10712  se lo daremos , seÃ±or ... y despuÃ©s la corona ...             NaN   \n",
       "10711  salieron nueve mercantes , cuatro pesqueros de...             NaN   \n",
       "10713                          los bosques de Campeche ,             NaN   \n",
       "16377  y callÃ³ , tal vez esperando una disculpa amant...             NaN   \n",
       "16375                    pero yo hijos no te voy a dar .             NaN   \n",
       "\n",
       "            age          gender  \\\n",
       "10712  thirties  male_masculine   \n",
       "10711  thirties  male_masculine   \n",
       "10713  thirties  male_masculine   \n",
       "16377   fifties  male_masculine   \n",
       "16375   fifties  male_masculine   \n",
       "\n",
       "                                                 accents locale  \n",
       "10712  EspaÃ±a: Norte peninsular (Asturias, Castilla y...     es  \n",
       "10711  EspaÃ±a: Norte peninsular (Asturias, Castilla y...     es  \n",
       "10713  EspaÃ±a: Norte peninsular (Asturias, Castilla y...     es  \n",
       "16377                                                NaN     es  \n",
       "16375                                                NaN     es  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On my device, all audio files are in the same \"clips\" folder. Please change the path if your files are in a different location.\n",
    "overview=preprocess_overview(overview, \"clips\")\n",
    "overview.sort_values(by=\"path\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a1035c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "client_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentence_domain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "accents",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "locale",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c10f927-127d-455d-af8e-0c87b723f018",
       "rows": [
        [
         "count",
         "29789",
         "29789",
         "29789",
         "2",
         "29666",
         "29789",
         "22434",
         "29789"
        ],
        [
         "unique",
         "6233",
         "29789",
         "24241",
         "2",
         "9",
         "2",
         "101",
         "1"
        ],
        [
         "top",
         "fffd6064784fc9c4162357a3a91e9e167b48bbf572da1c7568a283d0efdef6fea315833ed954b2813d051fc200e24232c4662f81f16893bae63ed17fa5b3458b",
         "clips/common_voice_es_19141587.mp3",
         "tres",
         "finance,language_fundamentals",
         "twenties",
         "male_masculine",
         "MÃ©xico",
         "es"
        ],
        [
         "freq",
         "5",
         "1",
         "406",
         "1",
         "13120",
         "21195",
         "5599",
         "29789"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_domain</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29789</td>\n",
       "      <td>29789</td>\n",
       "      <td>29789</td>\n",
       "      <td>2</td>\n",
       "      <td>29666</td>\n",
       "      <td>29789</td>\n",
       "      <td>22434</td>\n",
       "      <td>29789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6233</td>\n",
       "      <td>29789</td>\n",
       "      <td>24241</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>fffd6064784fc9c4162357a3a91e9e167b48bbf572da1c...</td>\n",
       "      <td>clips/common_voice_es_19141587.mp3</td>\n",
       "      <td>tres</td>\n",
       "      <td>finance,language_fundamentals</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male_masculine</td>\n",
       "      <td>MÃ©xico</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "      <td>13120</td>\n",
       "      <td>21195</td>\n",
       "      <td>5599</td>\n",
       "      <td>29789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id  \\\n",
       "count                                               29789   \n",
       "unique                                               6233   \n",
       "top     fffd6064784fc9c4162357a3a91e9e167b48bbf572da1c...   \n",
       "freq                                                    5   \n",
       "\n",
       "                                      path sentence  \\\n",
       "count                                29789    29789   \n",
       "unique                               29789    24241   \n",
       "top     clips/common_voice_es_19141587.mp3     tres   \n",
       "freq                                     1      406   \n",
       "\n",
       "                      sentence_domain       age          gender accents locale  \n",
       "count                               2     29666           29789   22434  29789  \n",
       "unique                              2         9               2     101      1  \n",
       "top     finance,language_fundamentals  twenties  male_masculine  MÃ©xico     es  \n",
       "freq                                1     13120           21195    5599  29789  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb4d983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "female_feminine     8594\n",
       "male_masculine     21195\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.groupby(\"gender\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80d938ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "eighties        18\n",
       "fifties       2354\n",
       "fourties      4292\n",
       "nineties         5\n",
       "seventies      101\n",
       "sixties        715\n",
       "teens         3248\n",
       "thirties      5813\n",
       "twenties     13120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.groupby(\"age\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10d301",
   "metadata": {},
   "source": [
    "We have a slight class imbalance that we may want to remove/have to deal with within the model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2a449",
   "metadata": {},
   "source": [
    "## Extraction of Audiofiles\n",
    "\n",
    "This step was necessary as the unpacking of the full tar files for EN & ES took too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ab2a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_files_flat(tar_path, file_paths, output_dir):\n",
    "    \"\"\"\n",
    "    Extract specific files from a tar archive into a flat output_dir.\n",
    "    Flattens the directory structure, extracting only the file name.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    successful = []\n",
    "    failed = []\n",
    "\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        for raw_path in tqdm(file_paths, desc=\"Extracting\"):\n",
    "            # Normalize path to forward slashes\n",
    "            path_in_tar = raw_path.replace(\"\\\\\", \"/\")\n",
    "            try:\n",
    "                member = tar.getmember(path_in_tar)\n",
    "                extracted_file = tar.extractfile(member)\n",
    "\n",
    "                if extracted_file is None:\n",
    "                    failed.append(path_in_tar)\n",
    "                    continue\n",
    "\n",
    "                # Get only the file name from the path (robust)\n",
    "                file_name = path_in_tar.split(\"/\")[-1]\n",
    "                out_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "                with open(out_path, \"wb\") as f:\n",
    "                    f.write(extracted_file.read())\n",
    "\n",
    "                if os.path.isfile(out_path):\n",
    "                    successful.append(path_in_tar)\n",
    "                else:\n",
    "                    failed.append(path_in_tar)\n",
    "\n",
    "            except KeyError:\n",
    "                failed.append(path_in_tar)\n",
    "\n",
    "    print(f\"Extracted {len(successful)} files.\")\n",
    "    if failed:\n",
    "        print(f\"Failed to extract {len(failed)} files.\")\n",
    "    return successful, failed\n",
    "\n",
    "\n",
    "\n",
    "def ensure_files_unpacked(tar_path, tar_internal_path, file_names, unpacked_dir):\n",
    "    \"\"\"\n",
    "    Ensure that selected files are unpacked in the given directory. \n",
    "    If any are missing, extract them from the tar archive.\n",
    "\n",
    "    Parameters:\n",
    "    - tar_path (str): Path to the .tar archive.\n",
    "    - tar_internal_path (str): Folder path inside the tar archive (e.g., \"data/\").\n",
    "    - file_names (list[str]): List of file names (not full paths) to check/extract.\n",
    "    - unpacked_dir (str): Directory where files should be unpacked.\n",
    "    \"\"\"\n",
    "\n",
    "    missing_files = []\n",
    "    once=True\n",
    "    for file_name in tqdm(file_names, desc=\"Checking existing files\", unit=\"file\"):\n",
    "        target_path = os.path.join(unpacked_dir, file_name)\n",
    "        if not os.path.isfile(target_path):\n",
    "            if once:\n",
    "                once=False\n",
    "                print(target_path)\n",
    "                print(tar_internal_path+\"/\"+file_name)\n",
    "            missing_files.append(tar_internal_path+\"/\"+file_name)\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"{len(missing_files)} files missing. Extracting...\")\n",
    "        extract_selected_files(tar_path, missing_files, unpacked_dir)\n",
    "    else:\n",
    "        print(\"All files are already present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05fa05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking existing files:   1%|â         | 438/29789 [00:00<00:13, 2203.44file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cv-corpus-21.0-2025-03-14/es\\clips/common_voice_es_34950484.mp3\n",
      "cv-corpus-21.0-2025-03-14/es/clips/common_voice_es_34950484.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking existing files: 100%|ââââââââââ| 29789/29789 [00:09<00:00, 3163.18file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2617 files missing. Extracting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|ââââââââââ| 2617/2617 [07:20<00:00,  5.95it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2617 files.\n"
     ]
    }
   ],
   "source": [
    "tar_path=\"./data/cv-corpus-21.0-2025-03-14-es.tar\"\n",
    "tar_internal_path=\"cv-corpus-21.0-2025-03-14/es\"\n",
    "ensure_files_unpacked(tar_path,tar_internal_path, overview[\"path\"],folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265589d",
   "metadata": {},
   "source": [
    "## Conversion of the Audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e071784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, alternate_path=None):\n",
    "    try:\n",
    "        # Use alternate_path if file_path is empty or invalid\n",
    "        if not file_path or not os.path.isfile(file_path):\n",
    "            if alternate_path and os.path.isfile(alternate_path):\n",
    "                file_path = alternate_path\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Neither file_path '{file_path}' nor alternate_path '{alternate_path}' is valid.\")\n",
    "\n",
    "        y, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "\n",
    "        # Feature extraction\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "\n",
    "        # Combine features into a single feature vector\n",
    "        features = np.hstack([\n",
    "            np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "            np.mean(chroma, axis=1), np.std(chroma, axis=1),\n",
    "            np.mean(spec_centroid), np.std(spec_centroid),\n",
    "            np.mean(spec_bw), np.std(spec_bw),\n",
    "            np.mean(spec_contrast, axis=1), np.std(spec_contrast, axis=1),\n",
    "            np.mean(spec_rolloff), np.std(spec_rolloff),\n",
    "            np.mean(zcr), np.std(zcr),\n",
    "            np.mean(rmse), np.std(rmse)\n",
    "        ])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04c02211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_columns():\n",
    "    columns = []\n",
    "    columns += [f\"mfcc_{i+1:02d}_mean\" for i in range(20)]\n",
    "    columns += [f\"mfcc_{i+1:02d}_std\" for i in range(20)]\n",
    "    columns += [f\"chroma_{i+1:02d}_mean\" for i in range(12)]\n",
    "    columns += [f\"chroma_{i+1:02d}_std\" for i in range(12)]\n",
    "    columns += [\"spec_centroid_mean\", \"spec_centroid_std\"]\n",
    "    columns += [\"spec_bandwidth_mean\", \"spec_bandwidth_std\"]\n",
    "    columns += [f\"spec_contrast_band_{i+1}_mean\" for i in range(7)]\n",
    "    columns += [f\"spec_contrast_band_{i+1}_std\" for i in range(7)]\n",
    "    columns += [\"spec_rolloff_mean\", \"spec_rolloff_std\"]\n",
    "    columns += [\"zcr_mean\", \"zcr_std\"]\n",
    "    columns += [\"rmse_mean\", \"rmse_std\"]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6112a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataframe(output_csv_path,df, folder_path,  alternate_folder_path=None, parallel=True):\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "\n",
    "    paths = [os.path.join(folder_path, name) for name in df[\"path\"]]\n",
    "    alternate_paths = [os.path.join(alternate_folder_path, name) for name in df[\"path\"]] if alternate_folder_path else [None] * len(paths)\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    # This helps to speed up the feature extraction process\n",
    "    if parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            futures = {executor.submit(extract_features, path, alt_path): idx for idx, (path, alt_path) in enumerate(zip(paths, alternate_paths))}\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(paths), desc=\"Extracting features\"):\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    features_list.append(result)\n",
    "                    valid_indices.append(futures[future])\n",
    "    else:\n",
    "        for idx, (path, alt_path) in tqdm(enumerate(zip(paths, alternate_paths)), total=len(paths), desc=\"Extracting features\"):\n",
    "            result = extract_features(path, alt_path)\n",
    "            if result is not None:\n",
    "                features_list.append(result)\n",
    "                valid_indices.append(idx)\n",
    "\n",
    "    # Build features DataFrame\n",
    "    columns = build_columns()\n",
    "    features_df = pd.DataFrame(features_list, columns=columns)\n",
    "    \n",
    "    # Match features to original DataFrame\n",
    "    merged_df = df.iloc[valid_indices].reset_index(drop=True)\n",
    "    final_df = pd.concat([merged_df, features_df], axis=1)\n",
    "\n",
    "    # Save to CSV\n",
    "    final_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Saved extracted features to {output_csv_path}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759b578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 117/29789 [00:14<48:27, 10.21it/s]  "
     ]
    }
   ],
   "source": [
    "df=extract_features_from_dataframe(\"./data/data_es_5.csv\", overview,folder_path, \"./data/cv-corpus-21.0-2025-03-14/es/cv-corpus-21.0-2025-03-14/es/\", parallel=True)\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
